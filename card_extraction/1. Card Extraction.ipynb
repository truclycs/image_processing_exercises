{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight: 0.11472916603088379s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from maskrcnn import MaskrcnnResnet50FPN\n",
    "import time\n",
    "\n",
    "num_classes = 3 # Background:0, card_front:1, card_back:2\n",
    "weight_path = '/home/vinhloiit/Documents/VTCC/id_info_extraction/models/weights/card_extraction/pytorch/2011110823/best_model_31_dice_mAP=0.9705.pt'\n",
    "\n",
    "model = MaskrcnnResnet50FPN(num_classes=num_classes)\n",
    "\n",
    "t1 = time.time()\n",
    "model.load_state_dict(torch.load(weight_path, map_location='cpu')) # Load weight\n",
    "t2 = time.time()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Chọn device nếu là GPU thì sẽ chuyển sang GPU\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Load weight: {t2 - t1}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "image_size = (768, 768)\n",
    "\n",
    "def preprocess(image):\n",
    "    sample = cv2.resize(image, dsize=image_size) #Resize ảnh về kích thước đầu vào của mạng\n",
    "    print('Image shape after resize', sample.shape)\n",
    "    \n",
    "    sample = torch.from_numpy(sample).to(torch.float).to(device)  #Chuyển ảnh từ kiểu dữ liệu numpy về torch\n",
    "    \n",
    "    # Thêm vào chiều đầu tiên là số lượng ảnh trong 1 batch -> (B, H, W, C)\n",
    "    # Chuyển (B, H, W, C) -> (B, C, H, W) cho phù hợp với input của mạng \n",
    "    samples = sample.unsqueeze(dim=0).permute(0, 3, 1, 2) \n",
    "    print('Image shape after unsqueeze and permute', samples.shape)\n",
    "    samples = (samples - samples.mean()) / samples.std() # normalization\n",
    "    return image, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape after resize (768, 768, 3)\n",
      "Image shape after unsqueeze and permute torch.Size([1, 3, 768, 768])\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test_images/input/cmnd.png')\n",
    "image, samples = preprocess(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for 2 images input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input many images\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "image_size = (768, 768)\n",
    "\n",
    "def preprocess(images):\n",
    "    samples = [cv2.resize(image, dsize=image_size) for image in images]\n",
    "    samples = np.stack(samples, axis=0) # dim = 0: number of images\n",
    "    samples = torch.from_numpy(samples).to(torch.float).to(device)\n",
    "    samples = samples.permute(0, 3, 1, 2)\n",
    "    samples = (samples - samples.mean()) / samples.std()\n",
    "    return images, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('test_images/input/cmnd.jpg')\n",
    "image2 = cv2.imread('test_images/input/cmnd.jpg')\n",
    "images = [image1, image2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, samples = preprocess(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(samples):\n",
    "    samples = samples.numpy()\n",
    "    samples = (samples - samples.min(axis=(1, 2, 3), keepdims=True)) / (samples.max(axis=(1, 2, 3), keepdims=True) - samples.min(axis=(1, 2, 3), keepdims=True))\n",
    "    samples = np.transpose(samples, axes=(0, 2, 3, 1))\n",
    "    samples = samples * 255\n",
    "    images = samples.astype(np.uint8)\n",
    "    return images\n",
    "\n",
    "images_ = denorm(samples)\n",
    "\n",
    "for sample in images_:\n",
    "    cv2.imshow('sample', sample)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(samples, image):\n",
    "    with torch.no_grad(): # Don't calculate backward\n",
    "        return model(samples), image #Return preds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_threshold = 0.6 # giá trị điểm ảnh < 0.6 ->0; > 0.6 -> 1\n",
    "contour_area_threshold = 0.03 \n",
    "vertical_threshold = 20 #Ngưỡng cho số cạnh của convexhull\n",
    "iou_threshold = 0.8 #Ngưỡng giao nhau của các box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point1, point2):\n",
    "    \"\"\"Distance between 2 points\"\"\"\n",
    "    point1 = np.float64(point1)\n",
    "    point2 = np.float64(point2)\n",
    "    return np.linalg.norm(point1 - point2) # point1 - point2: sub of 2 vectors --> calc norm of vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_point(line1, line2):\n",
    "    \"\"\"Find intersection of 2 lines\"\"\"\n",
    "    a1 = line1[1][1] - line1[0][1]\n",
    "    b1 = line1[0][0] - line1[1][0]\n",
    "    a2 = line2[1][1] - line2[0][1]\n",
    "    b2 = line2[0][0] - line2[1][0]\n",
    "    determinant = a1 * b2 - a2 * b1\n",
    "    if determinant == 0:\n",
    "        return None\n",
    "    c1 = (a1 / determinant) * line1[0][0] + (b1 / determinant) * line1[0][1]\n",
    "    c2 = (a2 / determinant) * line2[0][0] + (b2 / determinant) * line2[0][1]\n",
    "    x = b2 * c1 - b1 * c2\n",
    "    y = a1 * c2 - a2 * c1\n",
    "    return [int(x), int(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(polyA, polyB):\n",
    "    \"\"\"Compute ratio intersaction of 2 polygon\"\"\"\n",
    "    iou = 0.\n",
    "    polyA = geometry.Polygon(polyA) # Create polygon from list points\n",
    "    polyB = geometry.Polygon(polyB)\n",
    "    if polyA.intersects(polyB): # Check polyA intersect polyB?\n",
    "        iou = polyA.intersection(polyB).area / polyA.union(polyB).area \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(points):\n",
    "    \"\"\"\n",
    "    Sorting for points.\n",
    "    Args:\n",
    "        points (list): List 4 points\n",
    "    Returns:\n",
    "        [tl, tr, br, bl] (list): top left, top right, bottom right, bottom left\n",
    "    \"\"\"\n",
    "    assert len(points) == 4, 'Length of points must be 4'\n",
    "    left = sorted(points, key=lambda p: p[0])[:2]\n",
    "    right = sorted(points, key=lambda p: p[0])[2:]\n",
    "    tl, bl = sorted(left, key=lambda p: p[1])\n",
    "    tr, br = sorted(right, key=lambda p: p[1])\n",
    "    return [tl, tr, br, bl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convex_hulls(mask, binary_threshold, contour_area_threshold, vertical_threshold):\n",
    "    \"\"\"Get all convex hulls in image.\"\"\"\n",
    "    convex_hulls = []\n",
    "    \n",
    "    binary_image = (mask > binary_threshold).astype(np.uint8) # Convert to binary image\n",
    "    \n",
    "    binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, np.ones(shape=(5, 5), dtype=np.uint8)) # Remove noise\n",
    "    \n",
    "    num_label, label = cv2.connectedComponents(binary_image) # Get all components in mask\n",
    "    \n",
    "    for i in range(1, num_label):\n",
    "        # Find contour of each mask (mask = i), mask = 0 is background\n",
    "        contours = cv2.findContours((label == i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        \n",
    "        contour = contours[0] # 0: contour, 1: hierachy\n",
    "        \n",
    "        #chỉ lấy những mask có chu vi contour đủ lớn -> loại bỏ nhiễu\n",
    "        if cv2.contourArea(contour) > contour_area_threshold * mask.size: \n",
    "        \n",
    "            epsilon = 0.004 * cv2.arcLength(contour, closed=True) # arcLength: area\n",
    "            \n",
    "            approx_contour = cv2.approxPolyDP(contour, epsilon, closed=True)\n",
    "            \n",
    "            # approximate contour to reduce number of convex points\n",
    "            convex_hull = cv2.convexHull(approx_contour)  \n",
    "            \n",
    "            for inc in range(5):\n",
    "                #nếu số lượng điểm của convexhull đã nhỏ hơn số đỉnh (20) thì break\n",
    "                if convex_hull.shape[0] <= vertical_threshold: \n",
    "                    break\n",
    "                    \n",
    "                # approximate convex_hull to reduce number of convex points\n",
    "                epsilon = 0.002 * (1 + inc) * cv2.arcLength(contour, closed=True)\n",
    "                convex_hull = cv2.approxPolyDP(convex_hull, epsilon, closed=True)\n",
    "\n",
    "            #Chỉ lấy convexhull có số lượng điểm trong khoảng quy ước trước\n",
    "            #Vertical_threshold: Phải test trên số lượng lớn ảnh -> chọn ngưỡng phù hợp\n",
    "            if 4 <= convex_hull.shape[0] <= vertical_threshold: \n",
    "                #Vì convexhull trả về dạng nx1x2 -> nx2\n",
    "                convex_hulls.append(np.squeeze(np.array(convex_hull), axis=1)) \n",
    "\n",
    "    return convex_hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = cv2.imread('test_images/input/mask.png')\n",
    "mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) / 255.\n",
    "convex_hulls = get_convex_hulls(mask, binary_threshold, contour_area_threshold, vertical_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[308  74]\n",
      " [562  79]\n",
      " [681 606]\n",
      " [678 675]\n",
      " [338 704]\n",
      " [173 698]\n",
      " [146 636]\n",
      " [ 85 195]\n",
      " [ 94 167]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for convex_hull in convex_hulls:\n",
    "    print(convex_hull, type(convex_hull))\n",
    "    cv2.polylines(image, [convex_hull], True, (0, 255, 0), 3)\n",
    "    cv2.imshow('convex', image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import geometry\n",
    "import itertools\n",
    "\n",
    "def get_enclosed_quadrangles(mask, binary_threshold, contour_area_threshold, vertical_threshold, iou_threshold):\n",
    "    \"\"\"Get enclosed quadrangles (list 4 corners).\"\"\"\n",
    "    quadrangles = []\n",
    "    boundary = geometry.box(-mask.shape[1], -mask.shape[0], 2 * mask.shape[1], 2 * mask.shape[0]) #Boundary of intersection points\n",
    "    convex_hulls = get_convex_hulls(mask, binary_threshold, contour_area_threshold, vertical_threshold)\n",
    "    \n",
    "    for polygon in convex_hulls:\n",
    "        num_verticals = len(polygon) # number of verticals must be greater or equal 4\n",
    "        \n",
    "        quadrangle = None\n",
    "        \n",
    "        max_iou = 0\n",
    "        \n",
    "        for (x, y, z, t) in itertools.combinations(range(num_verticals), 4): #lệnh combination là kết hợp 4 đỉnh trong tập\n",
    "            lines = [\n",
    "                [polygon[x], polygon[(x + 1) % num_verticals]],\n",
    "                [polygon[y], polygon[(y + 1) % num_verticals]],\n",
    "                [polygon[z], polygon[(z + 1) % num_verticals]],\n",
    "                [polygon[t], polygon[(t + 1) % num_verticals]]\n",
    "            ]\n",
    "            \n",
    "            points = []\n",
    "            for i in range(4):\n",
    "                point = intersection_point(lines[i], lines[(i + 1) % 4]) # intersection point\n",
    "                \n",
    "                #Nếu không có giao điểm, hoặc giao điểm đó đã xét, hoặc nó không thuộc trong phạm vi cho phép thì break\n",
    "                if (not point) or (point in points) or (not boundary.contains(geometry.Point(point))): \n",
    "                    break\n",
    "                points.append(point)\n",
    "                \n",
    "            # Kiểm tra 4 điểm có phải là 1 polygon hay không \n",
    "            if len(points) == 4 and geometry.Polygon(order_points(points)).is_valid: \n",
    "                candidate_quadrangle = order_points(points) #Sắp xếp 4 đỉnh \n",
    "                iou = compute_iou(candidate_quadrangle, polygon) \n",
    "                if iou > max_iou and iou > iou_threshold:\n",
    "                    quadrangle = candidate_quadrangle\n",
    "                    max_iou = iou\n",
    "\n",
    "        if quadrangle:\n",
    "            quadrangles.append(quadrangle)\n",
    "\n",
    "    return quadrangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67, 69], [561, 79], [696, 673], [157, 719]] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test_images/input/mask.png')\n",
    "mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) / 255\n",
    "quadrangles = get_enclosed_quadrangles(mask, binary_threshold, contour_area_threshold, vertical_threshold, iou_threshold)\n",
    "for quad in quadrangles:\n",
    "    print(quad, type(quad))\n",
    "    cv2.polylines(image, [np.array(quad)], True, (0, 255, 0), 2)\n",
    "    cv2.imshow('quad', image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warped_images(image, mask_size, quadrangles):\n",
    "    warped_images = []\n",
    "    rh, rw = image.shape[0] / mask_size[0], image.shape[1] / mask_size[1]\n",
    "    # Chuyển về tọa độ của ảnh gốc \n",
    "    warped_locations = np.float32([[[point[0] * rw, point[1] * rh] for point in quad] for quad in quadrangles])\n",
    "\n",
    "    for quadrangle in warped_locations:\n",
    "        top_left, top_right, bottom_right, bottom_left = quadrangle\n",
    "\n",
    "        widthA = distance(bottom_right, bottom_left)\n",
    "        widthB = distance(top_right, top_left)\n",
    "        avgWidth = round((widthA + widthB) / 2)\n",
    "\n",
    "        heightA = distance(top_right, bottom_right)\n",
    "        heightB = distance(top_left, bottom_left)\n",
    "        avgHeight = round((heightA + heightB) / 2)\n",
    "\n",
    "        rectangle = np.float32([[0, 0], [avgWidth - 1, 0], [avgWidth - 1, avgHeight - 1], [0, avgHeight - 1]])\n",
    "\n",
    "        persp_matrix = cv2.getPerspectiveTransform(quadrangle, rectangle) # Căn đều 4 gốc thành hình chữ nhật \n",
    "        warped_image = cv2.warpPerspective(image, persp_matrix, (int(avgWidth), int(avgHeight)))\n",
    "        warped_images.append(warped_image)\n",
    "\n",
    "    return warped_images, warped_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_images/input/mask.png')\n",
    "mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "warped_images, warped_locations = get_warped_images(image, mask.shape, quadrangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for warped_image in warped_images:\n",
    "    cv2.imshow('warped image', warped_image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warped_scores(mask, quadrangles):\n",
    "    scores = []\n",
    "    for quadrangle in quadrangles:\n",
    "        # Prediction confidence\n",
    "        prediction_score = mask[mask.round().nonzero()].sum() / mask[mask.nonzero()].sum()\n",
    "        prediction_score = prediction_score.item()\n",
    "\n",
    "        # Postprocessing confidence\n",
    "        mask = mask.round()\n",
    "        card = np.zeros_like(mask, dtype=np.uint8)\n",
    "        card = cv2.fillPoly(card, np.int32([quadrangle]), (255, 255, 255)) / 255\n",
    "\n",
    "        inter = card * mask\n",
    "        union = (card + mask) != 0\n",
    "\n",
    "        postprocess_score = inter.sum(dtype=np.float32) / union.sum(dtype=np.float32)\n",
    "        postprocess_score = postprocess_score.item()\n",
    "\n",
    "        score = prediction_score * postprocess_score\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card_warper(image, mask):\n",
    "    quadrangles = get_enclosed_quadrangles(mask, binary_threshold, contour_area_threshold, vertical_threshold, iou_threshold)\n",
    "    warped_images, warped_locations = get_warped_images(image, mask.shape[:2], quadrangles)\n",
    "    warped_scores = get_warped_scores(mask, quadrangles)\n",
    "\n",
    "    return warped_images, warped_locations.tolist(), warped_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_iou_threshold = 0.4 # Loại bỏ box overlap \n",
    "card_area_threshold = 0.1\n",
    "pred_score_threshold = 0.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(preds, image):\n",
    "    pred = preds[0] # pytorch kết quả trả về ở idx 0\n",
    "\n",
    "    boxes, scores, masks = pred['boxes'], pred['scores'], pred['masks'] \n",
    "    # boxes: list các box của các card\n",
    "    # scores: \n",
    "    # masks: mask của từng card\n",
    "\n",
    "    indices = scores > pred_score_threshold  # Loại những box dưới ngưỡng # Lấy những idx có scores lớn hơn pred_score_threshold\n",
    "    boxes, scores, masks = boxes[indices], scores[indices], masks[indices] \n",
    "\n",
    "    indices = torchvision.ops.nms(boxes, scores, nms_iou_threshold)\n",
    "    masks = masks[indices]\n",
    "    masks = masks.squeeze(1).detach().cpu().numpy() #detach: loai bo gradient\n",
    "\n",
    "    _warped_cards, _warped_scores, _warped_locations = [], [], []\n",
    "    for mask in masks:\n",
    "        cards, locations, scores = card_warper(image, mask)\n",
    "        _warped_cards.extend(cards)\n",
    "        _warped_scores.extend(scores)\n",
    "        _warped_locations.extend(locations)\n",
    "\n",
    "    max_card_area = max([geometry.Polygon(location).area for location in _warped_locations]) if len(_warped_locations) else 0\n",
    "\n",
    "    warped_cards, warped_scores, warped_locations = [], [], []\n",
    "    for card, score, location in zip(_warped_cards, _warped_scores, _warped_locations):\n",
    "        if geometry.Polygon(location).area > card_area_threshold * max_card_area: # Chỉ lấy những card có kích thước đủ lớn\n",
    "            warped_cards.append(card)\n",
    "            warped_scores.append(score)\n",
    "            warped_locations.append(location)\n",
    "\n",
    "    return image, warped_cards, warped_scores, warped_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    if __debug__:\n",
    "        assert type(image).__name__ == 'ndarray', 'image must be ndarray.'\n",
    "        assert len(image.shape) == 3, 'image must be a 3D ndarray.'\n",
    "        assert image.shape[-1] == 3, 'image must have 3 channels.'\n",
    "    return image,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 process (Processsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape after resize (768, 768, 3)\n",
      "Image shape after unsqueeze and permute torch.Size([1, 3, 768, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinhloiit/.local/lib/python3.8/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "image = cv2.imread('test_images/input/cmnd.png')\n",
    "image, samples = preprocess(image)\n",
    "preds, image = process(samples, image)\n",
    "image, warped_cards, warped_scores, warped_locations = postprocess(preds, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warped_cards[0].shape\n",
    "cv2.imshow('warped_card', warped_cards[0])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('warped_card.jpg', warped_cards[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. postprocess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
