{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of gray image: (600, 600)\n",
      "max value: 255, min value: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1772a1a730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = cv2.imread('./test/example.png', cv2.IMREAD_GRAYSCALE)\n",
    "print(f'shape of gray image: {image.shape}')\n",
    "print(f'max value: {image.max()}, min value: {image.min()}')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Image to Binary Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./test/example.png')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected Components in Binary Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all connected components\n",
    "num_labels, labels = cv2.connectedComponents(binary_image)\n",
    "\n",
    "masks = []\n",
    "for i in range(1, num_labels):\n",
    "    mask = (labels == i).astype(np.uint8) * 255\n",
    "    masks.append(mask)\n",
    "    cv2.imshow(f'image_{i}', mask)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contours of Binary Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours:  1\n"
     ]
    }
   ],
   "source": [
    "# find convex hull of each mask in labels\n",
    "contours, hierarchy = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print('Number of contours: ', len(contours))\n",
    "for contour in contours:\n",
    "    dummy_image = image.copy()\n",
    "    cv2.drawContours(dummy_image, [contour], -1, (0, 255, 0), 3)\n",
    "    cv2.imshow('testing contour all image', dummy_image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex Hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mask = masks[0]\n",
    "contours, _ = cv2.findContours(testing_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "hull = cv2.convexHull(contours[0])\n",
    "polygon = np.squeeze(np.array(hull), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_hull = np.stack([testing_mask] * 3, axis=2)\n",
    "for i, point in enumerate(polygon):\n",
    "    cv2.circle(testing_hull, center=tuple(point), radius=3, color=(0, 0, 255), thickness=-1)\n",
    "    cv2.line(testing_hull, pt1=tuple(polygon[i % len(polygon)]), pt2=tuple(polygon[(i + 1) % len(polygon)]), color=(0, 255, 0), thickness=1)\n",
    "cv2.imshow('convex hull', testing_hull)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_contour = np.stack([testing_mask] * 3, axis=2)\n",
    "cv2.drawContours(testing_contour, [contour], -1, (0, 255, 0), 3)\n",
    "cv2.imshow('draw contour', testing_contour)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approx Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mask = masks[0]\n",
    "contours, _ = cv2.findContours(testing_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour = contours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour Perimeter\n",
    "perimeter = cv2.arcLength(contour, True)\n",
    "# contour approximation\n",
    "epsilon = 0.01 * perimeter\n",
    "approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "# approximation testing\n",
    "testing_approximation = np.stack([testing_mask] * 3, axis=2)\n",
    "cv2.drawContours(testing_approximation, [approx], -1, (0, 255, 0), 3)\n",
    "cv2.imshow('approx contour', testing_approximation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex Hull with Shapely.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mask = masks[0]\n",
    "contours, _ = cv2.findContours(testing_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour = np.squeeze(np.array(contours[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPoint\n",
    "convex_hull = MultiPoint(contour).convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"88.36 121.36 316.28 395.28\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,638.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.6351999999999998\" opacity=\"0.6\" d=\"M 247.0,136.0 L 105.0,141.0 L 103.0,143.0 L 103.0,162.0 L 125.0,500.0 L 127.0,502.0 L 258.0,502.0 L 386.0,498.0 L 388.0,497.0 L 390.0,495.0 L 390.0,491.0 L 389.0,140.0 L 386.0,137.0 L 334.0,136.0 L 247.0,136.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x7f177229d760>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"88.36 121.36 316.28 395.28\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,638.0)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"2.6351999999999998\" points=\"247.0,136.0 105.0,141.0 103.0,143.0 103.0,162.0 125.0,500.0 127.0,502.0 258.0,502.0 386.0,498.0 388.0,497.0 390.0,495.0 390.0,491.0 389.0,140.0 386.0,137.0 334.0,136.0 247.0,136.0\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.LinearRing at 0x7f17722f1eb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convex_hull.exterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(247.0, 136.0),\n",
       " (105.0, 141.0),\n",
       " (103.0, 143.0),\n",
       " (103.0, 162.0),\n",
       " (125.0, 500.0),\n",
       " (127.0, 502.0),\n",
       " (258.0, 502.0),\n",
       " (386.0, 498.0),\n",
       " (388.0, 497.0),\n",
       " (390.0, 495.0),\n",
       " (390.0, 491.0),\n",
       " (389.0, 140.0),\n",
       " (386.0, 137.0),\n",
       " (334.0, 136.0),\n",
       " (247.0, 136.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(convex_hull.exterior.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely.geometry import LineString\n",
    "\n",
    "# def find_intersection_point(line1, line2):\n",
    "#     line1 = LineString(line1)\n",
    "#     line2 = LineString(line2)\n",
    "#     point = None\n",
    "#     if line1.intersects(line2):\n",
    "#         point = line1.intersection(line2)\n",
    "#         point = point.x, point.y\n",
    "#     return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_point(line1, line2):\n",
    "    def get_slope(point1, point2):\n",
    "        if point1[0] == point2[0]:\n",
    "            return None\n",
    "        return (point1[1] - point2[1]) / (point1[0] - point2[0])\n",
    "\n",
    "    def get_intercept(slope, point):\n",
    "        return point[1] - slope * point[0]\n",
    "\n",
    "    slope1 = get_slope(line1[0], line1[1])\n",
    "    slope2 = get_slope(line2[0], line2[1])\n",
    "\n",
    "    if slope1 == slope2:\n",
    "        return None\n",
    "\n",
    "    b1 = get_intercept(slope1, line1[0])\n",
    "    b2 = get_intercept(slope2, line2[0])\n",
    "    inter_x = int((b1 - b2) / (slope2 - slope1))\n",
    "    inter_y = int(slope1 * inter_x + b1)\n",
    "\n",
    "    return [inter_x, inter_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(intersection_point(line1=[[0, 0], [0.5, 0.5]], line2=[[2, 0], [0, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function find convex hull of binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_convex_hulls(pred, binary_threshold=0.6, area_threshold=0.0, vertical_threshold=20):\n",
    "    convex_hulls = []\n",
    "    binary_image = (pred > binary_threshold).astype(np.uint8)\n",
    "    binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, np.ones(shape=(5, 5), dtype=np.uint8))\n",
    "    num_label, label = cv2.connectedComponents(binary_image)\n",
    "    for i in range(1, num_label):\n",
    "        contours, _ = cv2.findContours((label == i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour = contours[0]\n",
    "        if cv2.contourArea(contour) > area_threshold * pred.size:\n",
    "            epsilon = 0.009 * cv2.arcLength(contour, closed=True)\n",
    "            approx_contour = cv2.approxPolyDP(contour, epsilon, closed=True)\n",
    "            convex_hull = cv2.convexHull(approx_contour) # approximate contour to reduce num of points\n",
    "            for inc in range(5):\n",
    "                if convex_hull.shape[0] <= vertical_threshold:\n",
    "                    break\n",
    "                epsilon = 0.002 * (1 + inc) * cv2.arcLength(contour, closed=True)\n",
    "                convex_hull = cv2.approxPolyDP(convex_hull, epsilon, closed=True)\n",
    "\n",
    "            if 4 <= convex_hull.shape[0] <= vertical_threshold:\n",
    "                convex_hulls.append(np.squeeze(np.array(convex_hull), axis=1))\n",
    "\n",
    "    return convex_hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_convex_hull(pred, polygon):\n",
    "    testing_hull = np.stack([pred] * 3, axis=2)\n",
    "    for i, point in enumerate(polygon):\n",
    "        cv2.circle(testing_hull, center=tuple(point), radius=3, color=(0, 0, 255), thickness=-1)\n",
    "        cv2.line(testing_hull, pt1=tuple(polygon[i % len(polygon)]), pt2=tuple(polygon[(i + 1) % len(polygon)]), color=(0, 255, 0), thickness=1)\n",
    "    cv2.imshow('find convex hull', testing_hull)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cv2.imread('./test/example.png', cv2.IMREAD_GRAYSCALE) / 255\n",
    "convex_hulls = find_convex_hulls(pred)\n",
    "for polygon in convex_hulls:\n",
    "    show_convex_hull(pred, polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOU of 2 polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def compute_iou(polyA, polyB):\n",
    "    iou = 0.\n",
    "    polyA = Polygon(polyA)\n",
    "    polyB = Polygon(polyB)\n",
    "    if polyA.intersects(polyB):\n",
    "        iou = polyA.intersection(polyB).area / polyA.union(polyB).area\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyA = [[0, 0], [0, 2], [2, 2], [2, 0]]\n",
    "polyB = [[1, 1], [1, 3], [3, 3], [3, 1]]\n",
    "compute_iou(polyA, polyB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image, four_points):\n",
    "    four_points = np.array(four_points, dtype=np.float32)\n",
    "    (tl, tr, br, bl) = four_points\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    M = cv2.getPerspectiveTransform(four_points, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test/example.png', 0)\n",
    "warp = perspective_transform(image, [(100, 100), (300, 300), (0, 0), (0, 300)])\n",
    "cv2.imshow('warp', warp)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Enclosing Quadrileteral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "from shapely.geometry import box, Point, Polygon\n",
    "\n",
    "\n",
    "class EnclosingQuadrilateral:\n",
    "    def __init__(self):\n",
    "        self.binary_threshold = 0.6\n",
    "        self.area_threshold = 0.0\n",
    "        self.vertical_threshold = 20\n",
    "        self.iou_threshold = 0.8\n",
    "\n",
    "    def _order_points(self, points):\n",
    "        assert len(points) == 4, 'Length of points must be 4'\n",
    "        left = sorted(points, key=lambda p: p[0])[:2]\n",
    "        right = sorted(points, key=lambda p: p[0])[2:]\n",
    "        tl, bl = sorted(left, key=lambda p: p[1])\n",
    "        tr, br = sorted(right, key=lambda p: p[1])\n",
    "        return [tl, tr, br, bl]\n",
    "\n",
    "    def _compute_iou(self, polyA, polyB):\n",
    "        iou = 0.\n",
    "        polyA = Polygon(polyA)\n",
    "        polyB = Polygon(polyB)\n",
    "        if polyA.intersects(polyB):\n",
    "            iou = polyA.intersection(polyB).area / polyA.union(polyB).area\n",
    "        return iou\n",
    "\n",
    "    def _intersection_point(self, line1, line2):\n",
    "        a1 = line1[1][1] - line1[0][1]\n",
    "        b1 = line1[0][0] - line1[1][0]\n",
    "        a2 = line2[1][1] - line2[0][1]\n",
    "        b2 = line2[0][0] - line2[1][0]\n",
    "        determinant = a1 * b2 - a2 * b1\n",
    "        if determinant == 0:\n",
    "            return None\n",
    "        c1 = (a1 / determinant) * line1[0][0] + (b1 / determinant) * line1[0][1]\n",
    "        c2 = (a2 / determinant) * line2[0][0] + (b2 / determinant) * line2[0][1]\n",
    "        x = b2 * c1 - b1 * c2\n",
    "        y = a1 * c2 - a2 * c1\n",
    "        return [int(x), int(y)]\n",
    "\n",
    "    def _convex_hulls(self, pred, binary_threshold=0.6, area_threshold=0.0, vertical_threshold=20):\n",
    "        convex_hulls = []\n",
    "        binary_image = (pred > binary_threshold).astype(np.uint8)\n",
    "        binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, np.ones(shape=(5, 5), dtype=np.uint8))\n",
    "        num_label, label = cv2.connectedComponents(binary_image)\n",
    "        for i in range(1, num_label):\n",
    "            contours, _ = cv2.findContours((label == i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contour = contours[0]\n",
    "            if cv2.contourArea(contour) > area_threshold * pred.size:\n",
    "                epsilon = 0.009 * cv2.arcLength(contour, closed=True)\n",
    "                approx_contour = cv2.approxPolyDP(contour, epsilon, closed=True)\n",
    "                convex_hull = cv2.convexHull(approx_contour)  # approximate contour to reduce num of points\n",
    "                for inc in range(5):\n",
    "                    if convex_hull.shape[0] <= vertical_threshold:\n",
    "                        break\n",
    "                    epsilon = 0.002 * (1 + inc) * cv2.arcLength(contour, closed=True)\n",
    "                    convex_hull = cv2.approxPolyDP(convex_hull, epsilon, closed=True)\n",
    "\n",
    "                if 4 <= convex_hull.shape[0] <= vertical_threshold:\n",
    "                    convex_hulls.append(np.squeeze(np.array(convex_hull), axis=1))\n",
    "\n",
    "        return convex_hulls\n",
    "\n",
    "    def _enclosing_quadrilateral(self, pred, convex_hulls, iou_threshold):\n",
    "        enclosing_quads = []\n",
    "        x1, x2 = [-pred.shape[0], 2 * pred.shape[0]]\n",
    "        y1, y2 = [-pred.shape[1], 2 * pred.shape[1]]\n",
    "        boundary = box(x1, y1, x2, y2)\n",
    "        for polygon in convex_hulls:\n",
    "            num_verticals = len(polygon)\n",
    "            max_iou = 0.\n",
    "            enclosing_quad = None\n",
    "            for (x, y, z, t) in itertools.combinations(range(num_verticals), 4):\n",
    "                lines = [\n",
    "                    [polygon[x], polygon[(x + 1) % num_verticals]],\n",
    "                    [polygon[y], polygon[(y + 1) % num_verticals]],\n",
    "                    [polygon[z], polygon[(z + 1) % num_verticals]],\n",
    "                    [polygon[t], polygon[(t + 1) % num_verticals]]\n",
    "                ]\n",
    "                points = []\n",
    "                for i in range(4):\n",
    "                    point = self._intersection_point(lines[i], lines[(i + 1) % 4])\n",
    "                    if (not point) or (point in points) or (not boundary.contains(Point(point))):\n",
    "                        break\n",
    "                    points.append(point)\n",
    "\n",
    "                if len(points) == 4 and Polygon(self._order_points(points)).is_valid:\n",
    "                    candidate_quad = self._order_points(points)\n",
    "                    iou = self._compute_iou(candidate_quad, polygon)\n",
    "                    if iou > max_iou and iou > iou_threshold:\n",
    "                        enclosing_quad = candidate_quad\n",
    "                        max_iou = iou\n",
    "\n",
    "            if enclosing_quad:\n",
    "                enclosing_quads.append(enclosing_quad)\n",
    "\n",
    "        return enclosing_quads\n",
    "    \n",
    "    def perspective_transform(self, original_image, pred_mask, quad):\n",
    "        width_ratio = original_image.shape[1] / pred_mask.shape[1]\n",
    "        height_ratio = original_image.shape[0] / pred_mask.shape[0] \n",
    "        quad = np.array(quad, dtype=np.float32)\n",
    "        quad[:, 0] = quad[:, 0] * width_ratio\n",
    "        quad[:, 1] = quad[:, 1] * height_ratio\n",
    "        tl, tr, br, bl = quad\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [maxWidth - 1, 0],\n",
    "            [maxWidth - 1, maxHeight - 1],\n",
    "            [0, maxHeight - 1]], dtype = \"float32\")\n",
    "        M = cv2.getPerspectiveTransform(quad, dst)\n",
    "        warped_image = cv2.warpPerspective(original_image, M, (maxWidth, maxHeight))\n",
    "        return warped_image\n",
    "\n",
    "    def __call__(self, original_image, pred_mask):\n",
    "        warped_images = []\n",
    "        convex_hulls = self._convex_hulls(pred_mask,\n",
    "                                          self.binary_threshold,\n",
    "                                          self.area_threshold,\n",
    "                                          self.vertical_threshold)\n",
    "        enclosing_quads = self._enclosing_quadrilateral(pred_mask,\n",
    "                                                        convex_hulls,\n",
    "                                                        self.iou_threshold)\n",
    "        for quad in enclosing_quads:\n",
    "            warped_images.append(self.perspective_transform(original_image, pred_mask, quad))\n",
    "\n",
    "        return warped_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time: 0.005478620529174805\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "minEnclosingQuad = EnclosingQuadrilateral()\n",
    "orginal_image = cv2.imread('./test/mask.png')\n",
    "pred_mask = cv2.cvtColor(orginal_image, cv2.COLOR_BGR2GRAY) / 255.0\n",
    "t1 = time.time()\n",
    "warped_images = minEnclosingQuad(orginal_image, pred_mask)\n",
    "t2 = time.time()\n",
    "print(f'processing time: {t2 - t1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for warp_image in warped_images:\n",
    "    cv2.imshow('warped image', warp_image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quad in enclosing_quads:\n",
    "    quad = np.int32(quad)\n",
    "#     testing_quad = np.stack([pred] * 3, axis=2)\n",
    "    testing_quad = orginal_image.copy()\n",
    "    cv2.polylines(testing_quad, [quad], True, (255, 0, 0), 3)\n",
    "    cv2.imshow('find quad', testing_quad)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('./test/mask.jpg', cv2.IMREAD_GRAYSCALE) / 255.\n",
    "enclosing_quads = minEnclosingQuad(test_image)\n",
    "for quad in enclosing_quads:\n",
    "    quad = np.int32(quad)\n",
    "    test_quad = np.stack([pred] * 3, axis=2)\n",
    "    cv2.polylines(test_quad, [quad], True, (255, 0, 0), 3)\n",
    "    cv2.imshow('find quad', test_quad)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = minEnclosingQuad.perspective_transform(test_image, enclosing_quads[0])\n",
    "cv2.imshow('warp', warp)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('./test/mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "# https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged_image = cv2.Canny(binary_image, ret, 255)\n",
    "# https://docs.opencv.org/3.1.0/da/d22/tutorial_py_canny.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', edged_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn import MaskrcnnResnet50FPN\n",
    "import torch\n",
    "\n",
    "image_size = (768, 768)\n",
    "weight_path = './weight/2011110823/best_model_31_dice_mAP=0.9705.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskrcnnResnet50FPN(\n",
       "  (model): MaskRCNN(\n",
       "    (transform): GeneralizedRCNNTransform(\n",
       "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "        Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "    )\n",
       "    (backbone): BackboneWithFPN(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fpn): FeaturePyramidNetwork(\n",
       "        (inner_blocks): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (layer_blocks): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (extra_blocks): LastLevelMaxPool()\n",
       "      )\n",
       "    )\n",
       "    (rpn): RegionProposalNetwork(\n",
       "      (anchor_generator): AnchorGenerator()\n",
       "      (head): RPNHead(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (roi_heads): RoIHeads(\n",
       "      (box_roi_pool): MultiScaleRoIAlign()\n",
       "      (box_head): TwoMLPHead(\n",
       "        (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (box_predictor): FastRCNNPredictor(\n",
       "        (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
       "      )\n",
       "      (mask_roi_pool): MultiScaleRoIAlign()\n",
       "      (mask_head): MaskRCNNHeads(\n",
       "        (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu4): ReLU(inplace=True)\n",
       "      )\n",
       "      (mask_predictor): MaskRCNNPredictor(\n",
       "        (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (mask_fcn_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MaskrcnnResnet50FPN(num_classes=3)\n",
    "model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    '''\n",
    "    input: image: [H, W, C]\n",
    "    output: samples: [1, C, H', W']\n",
    "    '''\n",
    "    sample = cv2.resize(image, dsize=image_size)\n",
    "    sample = torch.from_numpy(sample).to(device).to(torch.float)\n",
    "    samples = sample.unsqueeze(dim=0).permute(0, 3, 1, 2)\n",
    "    samples = (samples - samples.mean(dim=(1, 2, 3))) / samples.std(dim=(1, 2, 3))\n",
    "    return image, samples\n",
    "\n",
    "def processing(image, samples):\n",
    "    with torch.no_grad():\n",
    "        preds = model(samples)\n",
    "    return image, preds\n",
    "\n",
    "def postprocessing(image, preds):\n",
    "    pred = preds[0]\n",
    "    boxes = pred['boxes']\n",
    "    masks = pred['masks']\n",
    "    scores = pred['scores']\n",
    "    labels = pred['labels']\n",
    "    \n",
    "    indices = scores > 0.5\n",
    "    masks = masks[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    indices = torchvision.ops.nms(boxes, scores, 0.5)\n",
    "    masks = masks[indices]\n",
    "    scores = scores[indices]\n",
    "    labels = labels[indices]  \n",
    "    \n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    masks = masks.squeeze(1).detach().cpu().numpy()\n",
    "    \n",
    "    return image, labels, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinhloiit/.local/lib/python3.8/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "test_image = cv2.imread('test/GiayCMND.png')\n",
    "image, samples = preprocessing(test_image)\n",
    "image, preds = processing(image, samples)\n",
    "image, labels, masks = postprocessing(image, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "minEnclosingQuad = EnclosingQuadrilateral()\n",
    "for mask in masks:\n",
    "    warped_images = minEnclosingQuad(test_image, mask)\n",
    "    for warped_image in warped_images:\n",
    "        cv2.imshow('result', warped_image)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
